{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede5222e-7fad-4402-b47d-bbd2717b5f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (4.41.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6841b396-98c6-4efd-ac34-054b47fc7727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b1a5485-ad82-4ace-94df-137b29f59f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from faiss-cpu) (23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c712f254-6eae-451a-a6fd-72f29b2012ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from sentence-transformers) (4.41.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from sentence-transformers) (0.23.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9539043c-2635-4e0c-9b25-8695524c48be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goutam.tak\\Anaconda\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pymysql.cursors\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6bef66b5-4a51-4253-a683-3ef93eea7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\goutam.tak\\Downloads\\employee_queries_dataset_large.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "80a99f82-9122-4564-b8a4-6c5889499602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the 'Prompt' column to remove NaNs and non-string values\n",
    "df['Prompt'] = df['Prompt'].fillna('').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a9522ff-2890-4a29-a396-177f256a77d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goutam.tak\\Anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load Sentence Transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4bb6462d-566b-4004-a9e2-941c5b003bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for the 'Prompt' column\n",
    "df['embeddings'] = df['Prompt'].apply(lambda x: model.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7abc14d0-9a8e-43c0-974b-3b6f68087cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embeddings to a format suitable for FAISS\n",
    "embeddings = np.stack(df['embeddings'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77cc5b5a-2d77-4733-8334-8afa735b6449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FAISS index\n",
    "d = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c8b5f8bb-b598-4320-a5bc-6c65d3737b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode a query using Sentence Transformer\n",
    "def encode_query(query, model):\n",
    "    return model.encode(query)\n",
    "def semantic_search_top_query(query, model, index, df, threshold=0.8):\n",
    "    query_embedding = encode_query(query, model)\n",
    "    D, I = index.search(np.array([query_embedding]), k=1)\n",
    "    distance = D[0][0]\n",
    "    retrieved_query = df.iloc[I[0][0]]['Query']\n",
    "\n",
    "    # Check if the distance is below the threshold\n",
    "    if distance <= threshold:\n",
    "        return retrieved_query\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa0b0652-27fc-4f63-a865-9e8c3d473f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql-connector-python\n",
      "  Downloading mysql_connector_python-8.4.0-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Downloading mysql_connector_python-8.4.0-cp311-cp311-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.5 MB 165.2 kB/s eta 0:01:28\n",
      "   ---------------------------------------- 0.0/14.5 MB 163.8 kB/s eta 0:01:29\n",
      "   ---------------------------------------- 0.0/14.5 MB 178.6 kB/s eta 0:01:21\n",
      "   ---------------------------------------- 0.1/14.5 MB 327.3 kB/s eta 0:00:44\n",
      "   ---------------------------------------- 0.2/14.5 MB 614.4 kB/s eta 0:00:24\n",
      "    --------------------------------------- 0.3/14.5 MB 896.4 kB/s eta 0:00:16\n",
      "   - -------------------------------------- 0.4/14.5 MB 1.2 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 0.8/14.5 MB 2.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.5/14.5 MB 3.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.6/14.5 MB 5.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.2/14.5 MB 8.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.6/14.5 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.2/14.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.4/14.5 MB 12.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.6/14.5 MB 13.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.7/14.5 MB 26.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.8/14.5 MB 28.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.1/14.5 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.3/14.5 MB 29.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.5 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.5 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.5 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.5 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 19.3 MB/s eta 0:00:00\n",
      "Installing collected packages: mysql-connector-python\n",
      "Successfully installed mysql-connector-python-8.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb223bf1-c959-46c0-a8b0-9da1211ca320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in c:\\users\\goutam.tak\\anaconda\\lib\\site-packages (8.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "72535ef5-b692-4a21-9fee-c21e0fe35798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Semantic search and execute SQL query\n",
    "query = \"Retrieve the full names and project names of employees who worked on projects\"\n",
    "retrieved_query = semantic_search_top_query(query, model, index, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cc712b99-a82e-4b73-8443-5bbaaaf6bc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT e.full_name, p.project_name FROM employees e JOIN employee_projects p ON e.employee_id = p.employee_id;'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cd66a7a9-cdb5-41ab-b509-0e21d49b5883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder function to execute an SQL query (adjust according to your database)\n",
    "import mysql.connector\n",
    "\n",
    "def execute_sql_query(query):\n",
    "    try:\n",
    "        # Connect to the MySQL database\n",
    "        connection = mysql.connector.connect(\n",
    "           host='ATMECSINLT-545',  # Adjust host if necessary\n",
    "            user='root',  # Replace with your MySQL username\n",
    "            password='1234',  # Replace with your MySQL password\n",
    "            database='task1'  # Database name\n",
    "        )\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        results = cursor.fetchall()\n",
    "        connection.close()\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while executing the SQL query: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "566418b7-a33a-4b1b-966a-a259bde9f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_with_bart(results):\n",
    "    input_text = \" \".join([str(row) for row in results])\n",
    "    input_ids = BartTokenizer.from_pretrained('facebook/bart-large').encode(input_text, return_tensors='pt')\n",
    "\n",
    "    # Load BART model and tokenizer\n",
    "    bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_ids = bart_model.generate(input_ids, max_length=512, num_beams=5, early_stopping=True)\n",
    "\n",
    "    response = BartTokenizer.from_pretrained('facebook/bart-large').decode(output_ids[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "82437a8f-09c3-4f11-8bdf-75a611f9db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(user_query, model, index, df):\n",
    "    retrieved_query = semantic_search_top_query(user_query, model, index, df)\n",
    "    if retrieved_query:\n",
    "        print(f\"Retrieved SQL Query: {retrieved_query}\")\n",
    "\n",
    "        results = execute_sql_query(retrieved_query)\n",
    "        if results:\n",
    "            print(\"\\nSQL Query Results:\")\n",
    "            for row in results:\n",
    "                print(f\"Result: {row}\")  # Adjust printing format based on your result structure\n",
    "\n",
    "            response = generate_response_with_bart(results)\n",
    "            print(\"\\nGenerated Response:\")\n",
    "            print(response)\n",
    "        else:\n",
    "            print(\"No results found for the executed query.\")\n",
    "    else:\n",
    "        print(\"No relevant query found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a96dc461-c5f5-4569-ae04-88e07ecff2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Retrieve the full names and project names of employees who worked on projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved SQL Query: SELECT e.full_name, p.project_name FROM employees e JOIN employee_projects p ON e.employee_id = p.employee_id;\n",
      "\n",
      "SQL Query Results:\n",
      "Result: ('John Doe', 'Project Alpha')\n",
      "Result: ('Jane Smith', 'Project Beta')\n",
      "Result: ('Emily Johnson', 'Project Gamma')\n",
      "\n",
      "Generated Response:\n",
      "('John Doe', 'Project Alpha') ('John Doe, 'Project Beta') ('Emily Johnson', 'project Gamma')\n"
     ]
    }
   ],
   "source": [
    "query=input(\"\")\n",
    "process_query(query, model, index, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b630d527-d41a-4b45-bae1-43ed0da5996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5180f6f4-14df-46ac-a735-de430c8d2283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import faiss\n",
    "\n",
    "# Save SentenceTransformer model\n",
    "model.save('sentence_transformer_model')\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, 'faiss_index')\n",
    "\n",
    "# Save DataFrame and other necessary objects\n",
    "with open('data_and_functions.pkl', 'wb') as f:\n",
    "    pickle.dump({'df': df, 'encode_query': encode_query, 'semantic_search_top_query': semantic_search_top_query, 'execute_sql_query': execute_sql_query, 'generate_response_with_bart': generate_response_with_bart, 'process_query': process_query}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "74132e12-f1c7-4e34-b490-8bf0c2d1ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load SentenceTransformer model\n",
    "model = SentenceTransformer('sentence_transformer_model')\n",
    "\n",
    "# Load FAISS index\n",
    "index = faiss.read_index('faiss_index')\n",
    "\n",
    "# Load DataFrame and other necessary objects\n",
    "with open('data_and_functions.pkl', 'rb') as f:\n",
    "    data_and_functions = pickle.load(f)\n",
    "\n",
    "df = data_and_functions['df']\n",
    "encode_query = data_and_functions['encode_query']\n",
    "semantic_search_top_query = data_and_functions['semantic_search_top_query']\n",
    "execute_sql_query = data_and_functions['execute_sql_query']\n",
    "generate_response_with_bart = data_and_functions['generate_response_with_bart']\n",
    "process_query = data_and_functions['process_query']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8bc292b7-7413-4a3d-8ff6-720f01084fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model, index, and data\n",
    "model.save('sentence_transformer_model')\n",
    "faiss.write_index(index, 'faiss_index.index')\n",
    "with open('data_and_functions.pkl', 'wb') as f:\n",
    "    pickle.dump({'df': df, 'encode_query': encode_query, 'semantic_search_top_query': semantic_search_top_query, 'execute_sql_query': execute_sql_query, 'generate_response_with_bart': generate_response_with_bart, 'process_query': process_query}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "902c5b63-cf1d-43d3-b21f-7183546117ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from IPython.display import FileLink, display\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "01449493-a954-4376-ac3b-0858a3fa8dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Path (<tt>sentence_transformer_model.zip</tt>) doesn't exist. It may still be in the process of being generated, or you may have the incorrect path."
      ],
      "text/plain": [
       "C:\\Users\\goutam.tak\\sentence_transformer_model.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='faiss_index.index' target='_blank'>faiss_index.index</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\goutam.tak\\faiss_index.index"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='data_and_functions.pkl' target='_blank'>data_and_functions.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\goutam.tak\\data_and_functions.pkl"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import FileLink, display\n",
    "\n",
    "# Create download links for individual files\n",
    "display(FileLink('sentence_transformer_model.zip'))\n",
    "display(FileLink('faiss_index.index'))\n",
    "display(FileLink('data_and_functions.pkl'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bb4f7e19-8929-4192-935c-8945ec76ba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\goutam.tak\\\\sentence_transformer_model.zip'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compress the SentenceTransformer model directory into a zip file\n",
    "shutil.make_archive('sentence_transformer_model', 'zip', 'sentence_transformer_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "495c9035-4b7b-4ec7-bfb7-f1d048d06b0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download links for the saved files:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='sentence_transformer_model.zip' target='_blank'>sentence_transformer_model.zip</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\goutam.tak\\sentence_transformer_model.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='faiss_index.index' target='_blank'>faiss_index.index</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\goutam.tak\\faiss_index.index"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='data_and_functions.pkl' target='_blank'>data_and_functions.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\goutam.tak\\data_and_functions.pkl"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create download links\n",
    "print(\"Download links for the saved files:\")\n",
    "display(FileLink('sentence_transformer_model.zip'))\n",
    "display(FileLink('faiss_index.index'))\n",
    "display(FileLink('data_and_functions.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37df149-8b1c-4a57-8a37-b18fd4dff295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
